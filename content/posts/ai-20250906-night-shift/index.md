+++
title = '深夜把模型当同事：一次“夜班排障”让我改了用法'
slug = 'ai-night-shift'
date = 2025-09-06T21:10:00+08:00
draft = false
tags = ['AI', '排障', '效率']
categories = ['AI']
summary = '那天加班到 11 点，我第一次认真把大模型当“值班同事”用：它不替我干活，但能把路灯点亮。'
toc = true
math = false
+++

那天的办公室很安静，空调出风口像在翻白眼。我盯着报错看了半小时，脑子里只剩两句话：

1) “这不应该啊。”
2) “我怎么又把它搞炸了。”

以前遇到这种情况，我会习惯性地去搜、去翻 Issue、去看别人踩过的坑。那天我突然换了个方法：把大模型当“同事”来用，而且是那种半夜也能被我拉起来一起值班的同事。

## 先别让它“给答案”，先让它“复述问题”

我一开始也犯老毛病：把报错贴过去，问“怎么修”。模型当然会给一大串建议，像菜市场摊主一样热情，甚至贴心地附上“可能原因一、二、三”。

但我很快发现：**这类建议真正有用的只有一半，另一半会把你带进更深的迷路。**

后来我改成这样问：

- “你先用自己的话复述一下你理解的问题是什么。”
- “你需要我补充哪些信息，才能把范围缩小到 3 个以内？”

这两句看起来很啰嗦，但效果出奇地好。它会主动问我：环境版本、触发条件、复现步骤、有没有改过配置。说真的，问得比我自己还像个认真排障的人。

## 我最满意的一招：让它写“排障清单”，而不是写“修复代码”

排障不是写代码，排障是“把不确定性挪走”。我让模型输出一个小清单：

- **先验证什么**（最便宜、最快的）
- **再验证什么**（能排掉一大片可能性）
- **最后才动哪里**（风险最高、最容易把问题越搞越大）

模型给的清单里，有一条很朴素：让我先把日志的时间范围扩大，别只盯着最后一行。结果真是“灯一开，蟑螂就跑”——我发现真正的异常出现在更早的某一步，只是后面才爆出来。

那一刻我有点好笑：我不是不会看日志，我只是太着急了。模型把我从“急着修”拽回“先确认”。

## 它也会胡说，但胡说也能被用起来

老实讲，模型也会一本正经地说错话。它会把两个版本的配置混在一起，会建议一些根本不存在的参数，会自信地说“你只要改 X 就行了”。

以前我会被这种自信吓到：要么全信，要么全不信。现在我更愿意把它当成“会说话的橡皮鸭”——你跟它解释一遍，你自己也会更清楚。

我给自己定了一个小规则：

- **凡是它给的“肯定句”，我都当成“待验证的假设”。**

比如它说“可能是缓存没清”。那我就问它：你认为缓存在哪个层？验证方式是什么？清了以后会出现什么变化？它答不上来，那就当它是瞎猜；它答得出来，我就按图索骥做个最小验证。

## 这次夜班之后，我改了三件事

1) **问题描述写得更像人**：我会把“现象 + 复现 + 期望”写完整，不再只贴报错截图。
2) **先要路径，不要答案**：它给我“怎么查”，比给我“怎么改”更值钱。
3) **所有建议都要落地到一个小实验**：能 30 秒验证的，别拖到 30 分钟。

回家路上我突然想到：大模型最像的不是“神仙”，也不是“实习生”，而是那种**能陪你把手电筒往黑处照一照**的同事。

它不会替你走路，但会提醒你：这里有台阶，那里有坑。

